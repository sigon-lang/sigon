[{'accuracy': 0.6121506690979004, 'loss': 3.363283395767212}, {'accuracy': 0.6358338594436646, 'loss': 2.2216410636901855}, {'accuracy': 0.784704864025116, 'loss': 1.173264741897583}, {'accuracy': 0.7563382387161255, 'loss': 2.0895767211914062}, {'accuracy': 0.7994875907897949, 'loss': 1.0851417779922485}, {'accuracy': 0.8412711024284363, 'loss': 1.2751327753067017}, {'accuracy': 0.7944744229316711, 'loss': 0.9966941475868225}, {'accuracy': 0.7943093180656433, 'loss': 1.274048924446106}, {'accuracy': 0.8814659714698792, 'loss': 0.4253084063529968}, {'accuracy': 0.8257399797439575, 'loss': 0.6542302966117859}, {'accuracy': 0.9339699745178223, 'loss': 0.18012966215610504}]


only 10 epochs

{'accuracy': 0.9567285776138306, 'loss': 0.10856504738330841}
3125/3125 [==============================] - 19s 6ms/step - loss: 2.1039 - accuracy: 0.5424
{'histories_evaluate': [{'accuracy': 0.9344090223312378, 'loss': 0.15877091884613037}, {'accuracy': 0.5561445951461792, 'loss': 2.343454360961914}, {'accuracy': 0.765273928642273, 'loss': 0.9969375729560852}, {'accuracy': 0.7412925958633423, 'loss': 1.6536850929260254}, {'accuracy': 0.6892098188400269, 'loss': 1.0491801500320435}, {'accuracy': 0.5983347296714783, 'loss': 1.4757448434829712}, {'accuracy': 0.5942124724388123, 'loss': 2.647082805633545}, {'accuracy': 0.623533308506012, 'loss': 1.1582294702529907}, {'accuracy': 0.5982252359390259, 'loss': 1.671897053718567}, {'accuracy': 0.4718332588672638, 'loss': 2.0029678344726562}, {'accuracy': 0.5107499957084656, 'loss': 3.747523546218872}, {'accuracy': 0.5424399971961975, 'loss': 2.1039483547210693}], 'histories_training': [{'accuracy': 0.9591361284255981, 'loss': 0.10111885517835617}, {'accuracy': 0.9582592844963074, 'loss': 0.10230296850204468}, {'accuracy': 0.8467344045639038, 'loss': 0.34623482823371887}, {'accuracy': 0.9420768022537231, 'loss': 0.13471728563308716}, {'accuracy': 0.8217222094535828, 'loss': 0.3780854642391205}, {'accuracy': 0.935906708240509, 'loss': 0.14970681071281433}, {'accuracy': 0.870258092880249, 'loss': 0.2883489727973938}, {'accuracy': 0.949200451374054, 'loss': 0.1181565374135971}, {'accuracy': 0.8653618693351746, 'loss': 0.30994266271591187}, {'accuracy': 0.950214684009552, 'loss': 0.12187805771827698}, {'accuracy': 0.8365997672080994, 'loss': 0.3734411597251892}, {'accuracy': 0.9437131285667419, 'loss': 0.13884414732456207}, {'accuracy': 0.8703117370605469, 'loss': 0.31293997168540955}, {'accuracy': 0.963160514831543, 'loss': 0.09350527822971344}, {'accuracy': 0.845582902431488, 'loss': 0.34920111298561096}, {'accuracy': 0.9417869448661804, 'loss': 0.13825470209121704}, {'accuracy': 0.8320360779762268, 'loss': 0.3876016438007355}, {'accuracy': 0.9482452273368835, 'loss': 0.12268216162919998}, {'accuracy': 0.8470961451530457, 'loss': 0.3560878336429596}, {'accuracy': 0.9708211421966553, 'loss': 0.07330876588821411}, {'accuracy': 0.8341571688652039, 'loss': 0.38817155361175537}, {'accuracy': 0.9639000296592712, 'loss': 0.09332390129566193}, {'accuracy': 0.8170999884605408, 'loss': 0.4092801809310913}, {'accuracy': 0.9567285776138306, 'loss': 0.10856504738330841}]}
5534.888902664185


with catastrophic forgetting

[{'accuracy': 0.7960073947906494, 'loss': 2.749032497406006}, {'accuracy': 0.6381587386131287, 'loss': 4.785417556762695}, {'accuracy': 0.7536182999610901, 'loss': 1.8407288789749146}, {'accuracy': 0.7832456231117249, 'loss': 2.2970972061157227}, {'accuracy': 0.7645931243896484, 'loss': 1.8465231657028198}, {'accuracy': 0.7602322101593018, 'loss': 1.618696689605713}, {'accuracy': 0.7822874188423157, 'loss': 2.323268413543701}, {'accuracy': 0.810742974281311, 'loss': 0.716382622718811}, {'accuracy': 0.8237983584403992, 'loss': 1.836588740348816}, {'accuracy': 0.8066053986549377, 'loss': 2.0582118034362793}, {'accuracy': 0.8218200206756592, 'loss': 1.3812228441238403}, {'accuracy': 0.9424499869346619, 'loss': 0.15415090322494507}]



TRAINING with proportion - month 12 should be desconsidered


[{'accuracy': 0.9034467339515686, 'loss': 0.22474658489227295}, {'accuracy': 0.8720837831497192, 'loss': 0.2898884117603302}, {'accuracy': 0.8557495474815369, 'loss': 0.32988297939300537}, {'accuracy': 0.8975077867507935, 'loss': 0.2404458075761795}, {'accuracy': 0.8820569515228271, 'loss': 0.2791444957256317}, {'accuracy': 0.8797752261161804, 'loss': 0.28429317474365234}, {'accuracy': 0.872620165348053, 'loss': 0.3052840828895569}, {'accuracy': 0.8641276955604553, 'loss': 0.30924269556999207}, {'accuracy': 0.7983399629592896, 'loss': 0.369913250207901}, {'accuracy': 0.8220311403274536, 'loss': 0.38429319858551025}, {'accuracy': 0.8990200161933899, 'loss': 0.2807594835758209}



proportion with subtract -- fine tuning only

[{'accuracy': 0.9129276275634766, 'loss': 0.203279048204422}, {'accuracy': 0.8850878477096558, 'loss': 0.26334187388420105}, {'accuracy': 0.8751595616340637, 'loss': 0.2947276532649994}, {'accuracy': 0.8969125747680664, 'loss': 0.2313195914030075}, {'accuracy': 0.8873932957649231, 'loss': 0.2647693455219269}, {'accuracy': 0.8275035619735718, 'loss': 0.3858262598514557}, {'accuracy': 0.7235565185546875, 'loss': 0.5882097482681274}, {'accuracy': 0.8355971574783325, 'loss': 0.34556838870048523}, {'accuracy': 0.7944208383560181, 'loss': 0.41582515835762024}, {'accuracy': 0.8245654702186584, 'loss': 0.4408877491950989}, {'accuracy': 0.898389995098114, 'loss': 0.2984594702720642}


proportion with subtract -- agent + nn 


[{'accuracy': 0.9024291634559631, 'loss': 0.23507942259311676}, {'accuracy': 0.8768494725227356, 'loss': 0.289756715297699}, {'accuracy': 0.8783142566680908, 'loss': 0.2778025269508362}, {'accuracy': 0.9010022878646851, 'loss': 0.23846176266670227}, {'accuracy': 0.9025744795799255, 'loss': 0.23304003477096558}, {'accuracy': 0.8709117770195007, 'loss': 0.29382428526878357}, {'accuracy': 0.8451994061470032, 'loss': 0.35738757252693176}, {'accuracy': 0.8693230748176575, 'loss': 0.3026183545589447}, {'accuracy': 0.8376109004020691, 'loss': 0.3632214367389679}, {'accuracy': 0.7027217745780945, 'loss': 0.4081673324108124}, {'accuracy': 0.9139599800109863, 'loss': 0.2737273573875427}, {'accuracy': 0.868340015411377, 'loss': 0.35648420453071594}]



fixed proportion -- agent + nn

[{'accuracy': 0.9128953218460083, 'loss': 0.2097465544939041}, {'accuracy': 0.8713449239730835, 'loss': 0.3017968237400055}, {'accuracy': 0.8887417316436768, 'loss': 0.25759080052375793}, {'accuracy': 0.9019814729690552, 'loss': 0.21784137189388275}, {'accuracy': 0.9149895310401917, 'loss': 0.20329122245311737}, {'accuracy': 0.8878535628318787, 'loss': 0.26670488715171814}, {'accuracy': 0.9057000279426575, 'loss': 0.2146756798028946}, {'accuracy': 0.8930985331535339, 'loss': 0.24505920708179474}, {'accuracy': 0.9153562784194946, 'loss': 0.1939195990562439}, {'accuracy': 0.9046450853347778, 'loss': 0.23637156188488007}, {'accuracy': 0.9002400040626526, 'loss': 0.24583131074905396}, {'accuracy': 0.8826799988746643, 'loss': 0.33256450295448303}]




2023-12-10 20:48:02.289402: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 615.23MiB (rounded to 645120000)requested by op _EagerConst
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.



without patience
{'accuracy': 0.9606714248657227, 'loss': 0.10250671952962875}
{'histories_evaluate': [], 'histories_training': [{'accuracy': 0.9517755508422852, 'loss': 0.11880835145711899}, {'accuracy': 0.9595745205879211, 'loss': 0.10039902478456497}, {'accuracy': 0.8628315329551697, 'loss': 0.3213244080543518}, {'accuracy': 0.943105936050415, 'loss': 0.13326884806156158}, {'accuracy': 0.8271579742431641, 'loss': 0.37507444620132446}, {'accuracy': 0.9395878314971924, 'loss': 0.14328953623771667}, {'accuracy': 0.8797761797904968, 'loss': 0.2732708156108856}, {'accuracy': 0.9556463956832886, 'loss': 0.10976891964673996}, {'accuracy': 0.878026008605957, 'loss': 0.28819718956947327}, {'accuracy': 0.9493123292922974, 'loss': 0.12037687003612518}, {'accuracy': 0.8322904109954834, 'loss': 0.37866291403770447}, {'accuracy': 0.9439492225646973, 'loss': 0.13866057991981506}, {'accuracy': 0.8725343346595764, 'loss': 0.31592217087745667}, {'accuracy': 0.9589653611183167, 'loss': 0.0986282005906105}, {'accuracy': 0.845205545425415, 'loss': 0.34621843695640564}, {'accuracy': 0.9447117447853088, 'loss': 0.13140764832496643}, {'accuracy': 0.8432108759880066, 'loss': 0.36446282267570496}, {'accuracy': 0.9455596804618835, 'loss': 0.12821538746356964}, {'accuracy': 0.8599745631217957, 'loss': 0.3534199297428131}, {'accuracy': 0.9690356850624084, 'loss': 0.07676879316568375}, {'accuracy': 0.8543428778648376, 'loss': 0.3615211248397827}, {'accuracy': 0.9659714102745056, 'loss': 0.09057135134935379}, {'accuracy': 0.8280428647994995, 'loss': 0.3951888382434845}, {'accuracy': 0.9606714248657227, 'loss': 0.10250671952962875}]}
2089.7962486743927

{'accuracy': 0.8628315329551697, 'loss': 0.3213244080543518}, {'accuracy': 0.9453489780426025, 'loss': 0.12955516576766968}, {'accuracy': 0.8271579742431641, 'loss': 0.37507444620132446}, {'accuracy': 0.9346337914466858, 'loss': 0.15360108017921448}, {'accuracy': 0.8797761797904968, 'loss': 0.2732708156108856}, {'accuracy': 0.9563595652580261, 'loss': 0.10572905838489532}, {'accuracy': 0.878026008605957, 'loss': 0.28819718956947327}, {'accuracy': 0.9490011930465698, 'loss': 0.11991685628890991}, {'accuracy': 0.8322904109954834, 'loss': 0.37866291403770447}, {'accuracy': 0.9415289163589478, 'loss': 0.14178356528282166}, {'accuracy': 0.8725343346595764, 'loss': 0.31592217087745667}, {'accuracy': 0.9578263163566589, 'loss': 0.10126496851444244}, {'accuracy': 0.845205545425415, 'loss': 0.34621843695640564}, {'accuracy': 0.9422901272773743, 'loss': 0.13409990072250366}, {'accuracy': 0.8432108759880066, 'loss': 0.36446282267570496}, {'accuracy': 0.9451727271080017, 'loss': 0.1260136514902115}, {'accuracy': 0.8599745631217957, 'loss': 0.3534199297428131}, {'accuracy': 0.9693828821182251, 'loss': 0.07678313553333282}, {'accuracy': 0.8543428778648376, 'loss': 0.3615211248397827}, {'accuracy': 0.9651142954826355, 'loss': 0.0919165313243866}, {'accuracy': 0.8280428647994995, 'loss': 0.3951888382434845}, {'accuracy': 0.960099995136261, 'loss': 0.10432448983192444}]}
2094.452375650406

